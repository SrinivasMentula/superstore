{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4405ce8e-47ec-4ca4-97d1-edc54fe6d377",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# importing the required libraries for the  the data processing\n",
    "from pyspark.sql.functions import trim, col, cast\n",
    "from pyspark.sql.types import DecimalType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528d671a-24e8-4cf5-944b-c85b5f016a66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/sarathazurelearning@gmail.com/superstore/Common/LoggingTableCreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0d32602-61f5-4eba-913b-d9c4f5be5ddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/sarathazurelearning@gmail.com/superstore/Common/logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0e8909b-d8eb-42a6-ad96-4be1e11c20f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/sarathazurelearning@gmail.com/superstore/StageLayer/stageTableCreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a81cd3d-14cf-4723-a48c-00e35f830b91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "NotebookName =( dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get().split(\"/\")[-1])\n",
    "Error_message = \"\"\n",
    "user_name = spark.sql('select user').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34c57908-ddaf-4547-b1e3-6cf7a37c4c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# trimming all the white spaces from the string column in the given inbound data\n",
    "\n",
    "# reading the  inbound  table as a data frame and trimming the string column to avoid the extra white spaces\n",
    "\n",
    "try:\n",
    "    inbound_df = spark.read.table(\"superstore.sales_reporting.sales_inbound\")\n",
    "    inbound_df = (\n",
    "        inbound_df.withColumn(\"shipMode\", trim(col(\"shipMode\")))\n",
    "        .withColumn(\"segment\", trim(col(\"segment\")))\n",
    "        .withColumn(\"country\", trim(col(\"country\")))\n",
    "        .withColumn(\"city\", trim(col(\"city\")))\n",
    "        .withColumn(\"state\", trim(col(\"state\")))\n",
    "        .withColumn(\"region\", trim((col(\"Region\"))))\n",
    "        .withColumn(\"category\", trim(col(\"category\")))\n",
    "        .withColumn(\"subCategory\", trim(col(\"subCategory\")))\n",
    "    )\n",
    "except Exception as e:\n",
    "    Error_message = str(e)\n",
    "    exceptionLogLoad(NotebookName, Error_message)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc1c7744-7485-472f-9755-d690c8740c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    inbound_df_columns = inbound_df.columns\n",
    "    required_columns = [i for i in inbound_df_columns if i != \"rowId\"]\n",
    "    inbound_df = inbound_df.select(*required_columns)\n",
    "    # replacing the - values into the  None values\n",
    "    inbound_df = inbound_df.replace(\"-\", None)\n",
    "    inbound_df = inbound_df.fillna(\n",
    "        {\n",
    "            \"shipMode\": \"Unkown\",\n",
    "            \"segment\": \"Unkown\",\n",
    "            \"country\": \"Unkown\",\n",
    "            \"city\": \"Unkown\",\n",
    "            \"state\": \"Unkown\",\n",
    "            \"postalCode\": 0,\n",
    "            \"region\": \"Unkown\",\n",
    "            \"category\": \"Unkown\",\n",
    "            \"subCategory\": \"Unkown\",\n",
    "            \"sales\": 0.0,\n",
    "            \"quantity\": 0,\n",
    "            \"discount\": 0.0,\n",
    "            \"profit\": 0.0,\n",
    "        }\n",
    "    )\n",
    "    rejected_records = inbound_df.filter(\"country is null\").filter(\n",
    "        \"sales < 0 or sales = 0 or quantity = 0\"\n",
    "    )\n",
    "    # creating a temp view to load the data\n",
    "    rejected_records.createOrReplaceTempView(\"rejectedRecordsTview\")\n",
    "    column_string = \",\".join(required_columns)\n",
    "except Exception as e:\n",
    "    Error_message = str(e)\n",
    "    exceptionLogLoad(NotebookName, Error_message)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dfa4014-99b4-405d-923f-1383352df15b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading the reject records into the  rejected table\n",
    "try:\n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "            \n",
    "            Insert into superstore.sales_reporting.rejectedsalesRecords\n",
    "            (\n",
    "              {column_string}\n",
    "            )\n",
    "            \n",
    "            select  {column_string}  from \n",
    "            rejectedRecordsTview\n",
    "            \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    Error_message = str(e)\n",
    "    exceptionLogLoad(NotebookName, Error_message)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75440dc7-b754-4b0d-8536-9c1dfed67e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# generating the stage layer columns\n",
    "try:\n",
    "    stageDf = inbound_df.withColumn(\n",
    "        \"revenueAfterDiscount\",\n",
    "         (col(\"sales\") - (col(\"sales\") * col(\"discount\"))).cast(DecimalType(20, 4)),\n",
    "    ).withColumn(\"profitMargin\", (col(\"profit\") / col(\"sales\")) * 100)\n",
    "    stageTableColumns = stageDf.columns\n",
    "    stageColumnsString = \",\".join(stageTableColumns)\n",
    "    # print(stageColumnsString)\n",
    "    # tempview creation onthe stage DF\n",
    "    stageDf.createOrReplaceTempView(\"stageTableTView\")\n",
    "\n",
    "    # loading the data into the stage layer table\n",
    "    truncate_query = \" Truncate table superstore.sales_reporting.staging \"\n",
    "\n",
    "    query = f\"\"\"INSERT INTO superstore.sales_reporting.staging \n",
    "            (  \n",
    "              {stageColumnsString}\n",
    "            )\n",
    "            SELECT \n",
    "            {stageColumnsString}\n",
    "            FROM \n",
    "            stageTableTView\n",
    "            \"\"\"\n",
    "    spark.sql(query)\n",
    "except Exception as e:\n",
    "    Error_message = str(e)\n",
    "    exceptionLogLoad(NotebookName, Error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56b3a767-e018-4281-b84a-e7852c1cfd4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SELECT  * FROM sales_reporting.staging"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8463588835955282,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "StageLayerConfiguration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
